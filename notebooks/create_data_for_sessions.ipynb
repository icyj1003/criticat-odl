{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "CUR_DIR = os.path.abspath(os.curdir)\n",
    "CACHE_DIR = os.path.join(CUR_DIR, \"../.cache/\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataloader from cache with chunk size 128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"..\")\n",
    "\n",
    "from utils import *\n",
    "from vocabulary import Vocabulary\n",
    "from cusdataset import TestingDataset\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "cache = open(os.path.join(CACHE_DIR, \"pretrain_dataset_with_image.pkl\"), \"rb\")\n",
    "raw_data = pickle.load(cache)\n",
    "cache.close()\n",
    "\n",
    "\n",
    "# create dataloader\n",
    "dataset = TestingDataset(raw_data)\n",
    "dataloader = DataLoader(dataset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split dataset into batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdb656e78eb544c6860802f85c5ee96b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating sessions data: : 0sessions [00:00, ?sessions/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# user lut\n",
    "lut = Vocabulary(specials=[\"<unk>\"])\n",
    "lut.set_default_idx(lut[\"<unk>\"])\n",
    "\n",
    "# text vocab\n",
    "vc = Vocabulary(specials=[\"<pad>\", \"<unk>\"])\n",
    "vc.set_default_idx(vc[\"<unk>\"])\n",
    "\n",
    "train_texts_total = None\n",
    "raw_train_text_total = []\n",
    "test_texts_total = []\n",
    "\n",
    "train_images_total = None\n",
    "test_images_total = None\n",
    "\n",
    "train_user_name_total = None\n",
    "test_user_name_total = []\n",
    "\n",
    "train_metadata_total = None\n",
    "test_metadata_total = None\n",
    "\n",
    "train_labels_total = None\n",
    "test_labels_total = None\n",
    "\n",
    "for idx, batch in tqdm(\n",
    "    enumerate(dataloader), desc=\"Creating sessions data: \", unit=\"sessions\"\n",
    "):\n",
    "    # * Target\n",
    "    labels = batch[\"label\"]\n",
    "\n",
    "    stratify = labels\n",
    "    dummy_input = torch.tensor(list(range(len(labels))))\n",
    "\n",
    "    train_idx, test_idx, train_labels, test_labels = train_test_split(\n",
    "        dummy_input, labels, test_size=0.1, shuffle=True, stratify=stratify\n",
    "    )\n",
    "\n",
    "    # * Text content\n",
    "    raw_train_texts = [batch[\"post_message\"][i] for i in train_idx]\n",
    "    raw_train_text_total += raw_train_texts\n",
    "    train_texts = handling_text(raw_train_texts, vc, train=True)\n",
    "    raw_test_texts = [batch[\"post_message\"][i] for i in test_idx]\n",
    "    test_texts_total += raw_test_texts\n",
    "    test_texts = handling_text(raw_test_texts, vc, train=False)\n",
    "\n",
    "    # * Images\n",
    "    images = batch[\"image\"]\n",
    "\n",
    "    # * Username\n",
    "    train_user_name = [batch[\"user_name\"][i] for i in train_idx]\n",
    "    train_user_name = handling_username(train_user_name, lut, train=True)\n",
    "    test_user_name = [batch[\"user_name\"][i] for i in test_idx]\n",
    "    test_user_name_total += test_user_name\n",
    "    test_user_name = handling_username(test_user_name, lut, train=False)\n",
    "\n",
    "    # * Metadata\n",
    "    metadata = handling_metadata(\n",
    "        num_like_post=batch[\"num_like_post\"],\n",
    "        num_comment_post=batch[\"num_comment_post\"],\n",
    "        num_share_post=batch[\"num_share_post\"],\n",
    "        raw_length=batch[\"raw_length\"],\n",
    "        timestamp_post=batch[\"timestamp_post\"],\n",
    "    )\n",
    "    # append to total\n",
    "    # text ======\n",
    "    train_texts_total = (\n",
    "        torch.cat([train_texts_total, train_texts])\n",
    "        if train_texts_total != None\n",
    "        else train_texts\n",
    "    )\n",
    "    # image ======\n",
    "    train_images_total = (\n",
    "        torch.cat([train_images_total, images[train_idx]])\n",
    "        if train_images_total != None\n",
    "        else images[train_idx]\n",
    "    )\n",
    "\n",
    "    test_images_total = (\n",
    "        torch.cat([test_images_total, images[test_idx]])\n",
    "        if test_images_total != None\n",
    "        else images[test_idx]\n",
    "    )\n",
    "    # username ======\n",
    "    train_user_name_total = (\n",
    "        torch.cat([train_user_name_total, train_user_name])\n",
    "        if train_user_name_total != None\n",
    "        else train_user_name\n",
    "    )\n",
    "    # metadata ======\n",
    "    train_metadata_total = (\n",
    "        torch.cat([train_metadata_total, metadata[train_idx]])\n",
    "        if train_metadata_total != None\n",
    "        else metadata[train_idx]\n",
    "    )\n",
    "\n",
    "    test_metadata_total = (\n",
    "        torch.cat([test_metadata_total, metadata[test_idx]])\n",
    "        if test_metadata_total != None\n",
    "        else metadata[test_idx]\n",
    "    )\n",
    "\n",
    "    # label ======\n",
    "    train_labels_total = (\n",
    "        torch.cat([train_labels_total, train_labels])\n",
    "        if train_labels_total != None\n",
    "        else train_labels\n",
    "    )\n",
    "\n",
    "    test_labels_total = (\n",
    "        torch.cat([test_labels_total, test_labels])\n",
    "        if test_labels_total != None\n",
    "        else test_labels\n",
    "    )\n",
    "    # save session data\n",
    "    train_inputs = {\n",
    "        \"texts\": train_texts,\n",
    "        \"raw_texts\": raw_train_texts,\n",
    "        \"images\": images[train_idx],\n",
    "        \"user_name\": train_user_name,\n",
    "        \"metadata\": metadata[train_idx],\n",
    "    }\n",
    "    test_inputs = {\n",
    "        \"texts\": test_texts,\n",
    "        \"raw_texts\": raw_test_texts,\n",
    "        \"images\": images[test_idx],\n",
    "        \"user_name\": test_user_name,\n",
    "        \"metadata\": metadata[test_idx],\n",
    "    }\n",
    "\n",
    "    session_dataset = {\n",
    "        \"train_inputs\": train_inputs,\n",
    "        \"test_inputs\": test_inputs,\n",
    "        \"train_labels\": train_labels,\n",
    "        \"test_label\": test_labels,\n",
    "    }\n",
    "\n",
    "    torch.save(\n",
    "        {\"vocabulary\": vc, \"LUT\": lut, \"dataset\": session_dataset},\n",
    "        os.path.join(CACHE_DIR, f\"sessions/session_{idx}.pt\"),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_texts_total_1 = handling_text(test_texts_total, vc, False)\n",
    "test_user_name_total_1 = handling_text(test_user_name_total, vc, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs_total = {\n",
    "    \"texts\": train_texts_total,\n",
    "    \"raw_texts\": raw_train_text_total,\n",
    "    \"images\": train_images_total,\n",
    "    \"user_name\": train_user_name_total,\n",
    "    \"metadata\": train_metadata_total,\n",
    "}\n",
    "\n",
    "test_inputs_total = {\n",
    "    \"texts\": test_texts_total_1,\n",
    "    \"raw_texts\": test_texts_total,\n",
    "    \"images\": test_images_total,\n",
    "    \"user_name\": test_user_name_total_1,\n",
    "    \"metadata\": test_metadata_total,\n",
    "}\n",
    "\n",
    "final_dataset = {\n",
    "    \"train_inputs\": train_inputs_total,\n",
    "    \"test_inputs\": test_inputs_total,\n",
    "    \"train_labels\": train_labels_total,\n",
    "    \"test_label\": test_labels_total,\n",
    "}\n",
    "\n",
    "torch.save(\n",
    "    {\"vocabulary\": vc, \"LUT\": lut, \"dataset\": final_dataset},\n",
    "    os.path.join(CACHE_DIR, f\"dataset.pt\"),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
