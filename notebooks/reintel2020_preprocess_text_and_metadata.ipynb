{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"..\")\n",
    "from preprocess import VietnameseTextCleaner\n",
    "from utils import dict_handler\n",
    "\n",
    "\n",
    "matplotlib.style.use(\"ggplot\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUR_DIR = os.path.abspath(os.curdir)\n",
    "METADATA_PATH = os.path.join(CUR_DIR, \"../data/reintel2020/public_train.csv\")\n",
    "IMAGES_DIR = os.path.join(CUR_DIR, \"../data/reintel2020/public_train_final_images/\")\n",
    "CACHE_PATH = os.path.join(CUR_DIR, \"../.cache/\")\n",
    "VNCORE_NLP_PATH = os.path.join(CUR_DIR, \"../vncorenlp/\")\n",
    "STOPWORDS_PATH = os.path.join(CUR_DIR, \"../stop_words/vietnamese-stopwords-dash.txt\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init Cleaner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaner = VietnameseTextCleaner(\n",
    "    stopwords_path=STOPWORDS_PATH,\n",
    "    vncorenlp_path=VNCORE_NLP_PATH,\n",
    "    cur_dir=CUR_DIR,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(METADATA_PATH)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixing timestamp errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type errors\n",
    "errors = []\n",
    "for i in range(len(df_train[\"timestamp_post\"])):\n",
    "    try:\n",
    "        float(df_train[\"timestamp_post\"][i])\n",
    "    except:\n",
    "        errors.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing\n",
    "missings = df_train[df_train.timestamp_post.isnull()].index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4372 entries, 0 to 4371\n",
      "Data columns (total 8 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   id                4372 non-null   int64  \n",
      " 1   user_name         4372 non-null   object \n",
      " 2   post_message      4371 non-null   object \n",
      " 3   timestamp_post    4372 non-null   float64\n",
      " 4   num_like_post     4257 non-null   object \n",
      " 5   num_comment_post  4362 non-null   object \n",
      " 6   num_share_post    3647 non-null   object \n",
      " 7   label             4372 non-null   int64  \n",
      "dtypes: float64(1), int64(2), object(5)\n",
      "memory usage: 273.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# fill with mean\n",
    "mean = (\n",
    "    df_train[~df_train.index.isin(missings + errors)][\"timestamp_post\"]\n",
    "    .astype(float)\n",
    "    .mean()\n",
    ")\n",
    "df_train.loc[errors + missings, \"timestamp_post\"] = mean\n",
    "df_train.timestamp_post = df_train.timestamp_post.astype(float)\n",
    "df_train.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sort by timestamp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted = df_train.sort_values(\"timestamp_post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa33d754ee6e4a5896c9b63525502aff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4372 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = [\n",
    "    dict_handler(dict_object=record, cleaner=cleaner)\n",
    "    for record in tqdm(df_sorted.to_dict(\"records\"))\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save dataset as cache\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = open(os.path.join(CACHE_PATH, \"pretrain_dataset.pkl\"), \"wb\")\n",
    "pickle.dump(dataset, cache)\n",
    "cache.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
