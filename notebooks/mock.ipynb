{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torchvision import models\n",
    "import torchtext.transforms as TT\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from typing import List, Any\n",
    "import torchvision.transforms as IT\n",
    "import re\n",
    "from torchtext.vocab import vocab\n",
    "from faker import Faker\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "faker = Faker()\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"..\")\n",
    "\n",
    "from trainer import Trainer\n",
    "\n",
    "\n",
    "def LDtoDL(l):\n",
    "    result = {}\n",
    "    for d in l:\n",
    "        for k, v in d.items():\n",
    "            result[k] = result.get(k, []) + [v]\n",
    "    return result\n",
    "\n",
    "\n",
    "def DLtoLD(d):\n",
    "    if not d:\n",
    "        return []\n",
    "    result = [{} for i in range(max(map(len, d.values())))]\n",
    "    for k, seq in d.items():\n",
    "        for oneDict, oneValue in zip(result, seq):\n",
    "            oneDict[k] = oneValue\n",
    "    return result\n",
    "\n",
    "\n",
    "class TestingDataset(Dataset):\n",
    "    def __init__(self, data: List[dict]) -> None:\n",
    "        self.data = data\n",
    "\n",
    "    def __getitem__(self, index) -> Any:\n",
    "        return self.data[index]\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "class TextTransform(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TextTransform, self).__init__()\n",
    "        self.toTensor = TT.ToTensor()\n",
    "        self.padding = TT.PadTransform(20, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.toTensor(x)\n",
    "        x = x[:20]\n",
    "        x = self.padding(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_classes):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=1, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        embedded = self.embedding(inputs)\n",
    "        out, _ = self.lstm(embedded)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return F.softmax(out)\n",
    "\n",
    "\n",
    "class Resnet18(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(Resnet18, self).__init__()\n",
    "        self.model = models.resnet18(weights=\"ResNet18_Weights.DEFAULT\")\n",
    "        self.model.fc = nn.Linear(self.model.fc.in_features, num_classes)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        out = self.model(inputs)\n",
    "        return F.softmax(out)\n",
    "\n",
    "\n",
    "class EnsembleModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        text_model: LSTMClassifier,\n",
    "        image_model: Resnet18,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.text_model = text_model\n",
    "        self.image_model = image_model\n",
    "        self.metadata_model = image_model\n",
    "        self.fc = nn.Linear(\n",
    "            text_model.fc.out_features + image_model.model.fc.out_features, 2\n",
    "        )\n",
    "\n",
    "    def forward(self, text, image, metadata):\n",
    "        text_out = self.text_model(text)\n",
    "        image_out = self.image_model(image)\n",
    "        combined = torch.cat((text_out, image_out), dim=1)\n",
    "        out = self.fc(combined)\n",
    "        return out\n",
    "\n",
    "\n",
    "image_transform = IT.Compose(\n",
    "    [\n",
    "        IT.Resize(256),\n",
    "        IT.CenterCrop(224),\n",
    "        IT.ToTensor(),\n",
    "        IT.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "text_transform = TextTransform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_proprocess(texts):\n",
    "    return re.match(r\"[a-z, ]*\", texts)[0].split()\n",
    "\n",
    "\n",
    "vc = vocab({}, specials=[\"<pad>\", \"<unk>\"])\n",
    "vc.set_default_index(vc[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lenght = 10000\n",
    "mock_df = pd.DataFrame(\n",
    "    data={\n",
    "        \"post_message\": [faker.text() for _ in range(df_lenght)],\n",
    "        # \"num_like_post\": [random.randint(0, 10000) for _ in range(df_lenght)],\n",
    "        # \"user_id\": [faker.name() for _ in range(df_lenght)],\n",
    "        # \"num_comment_post\": [random.randint(0, 10000) for _ in range(df_lenght)],\n",
    "        # \"num_share_post\": [random.randint(0, 10000) for _ in range(df_lenght)],\n",
    "        \"label\": [random.randint(0, 1) for _ in range(df_lenght)],\n",
    "    }\n",
    ")\n",
    "\n",
    "mock_df[\"post_message\"] = mock_df[\"post_message\"].map(lambda x: x.lower())\n",
    "mock_df[\"images\"] = mock_df[\"post_message\"].map(lambda x: torch.rand(3, 256, 256))\n",
    "mock_dataset = list(mock_df.to_dict(\"index\").values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TestingDataset(mock_dataset[: int(len(mock_dataset) * 0.8)])\n",
    "test_dataset = TestingDataset(mock_dataset[int(len(mock_dataset) * 0.8) :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = DataLoader(train_dataset, batch_size=4)\n",
    "test_iter = DataLoader(test_dataset, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['question', 'main', 'manager', 'community', 'behind', 'policy', 'left'], ['travel', 'wait', 'white', 'quality', 'finish'], ['though', 'few', 'court', 'billion', 'organization', 'physical', 'nearly'], ['note', 'on', 'baby', 'public', 'on', 'put', 'entire']]\n"
     ]
    }
   ],
   "source": [
    "for batch in train_iter:\n",
    "    clean_text = [text_proprocess(text) for text in batch[\"post_message\"]]\n",
    "    print(clean_text)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
