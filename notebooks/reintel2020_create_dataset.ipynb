{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anhbu\\miniconda3\\envs\\odl\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import sys\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "sys.path.insert(0, \"..\")\n",
    "\n",
    "from utils import ensure_dir_exists\n",
    "\n",
    "from customdataset import TestingDataset\n",
    "\n",
    "CUR_DIR = os.path.abspath(os.curdir)\n",
    "SAVE_DIR_ONLINE = \"E:\\\\tools\\\\new_odl\\\\cache\\\\online_session\\\\reintel2020\\\\\"\n",
    "CACHE_DIR = (\n",
    "    \"E:\\\\tools\\\\new_odl\\\\cache\\\\clean_metadata_with_image\\\\reintel2020\\\\\"\n",
    ")\n",
    "\n",
    "for dir in [SAVE_DIR_ONLINE]:\n",
    "    ensure_dir_exists(dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset: 700 | test_dataset: 175\n",
      "Saved dataset_01.pt with size: 689232882 bytes\n",
      "train_dataset: 700 | test_dataset: 175\n",
      "Saved dataset_02.pt with size: 689093234 bytes\n",
      "train_dataset: 700 | test_dataset: 175\n",
      "Saved dataset_03.pt with size: 688962994 bytes\n",
      "train_dataset: 700 | test_dataset: 175\n",
      "Saved dataset_04.pt with size: 689028338 bytes\n",
      "train_dataset: 697 | test_dataset: 175\n",
      "Saved dataset_05.pt with size: 686538735 bytes\n"
     ]
    }
   ],
   "source": [
    "for i, cache_file in enumerate(os.listdir(CACHE_DIR)):\n",
    "    # create dataset from cache\n",
    "    dataset = TestingDataset(torch.load(os.path.join(CACHE_DIR, cache_file)))\n",
    "\n",
    "    # get indices and labels\n",
    "    x = list(range(len(dataset)))\n",
    "    y = dataset.get_labels()\n",
    "\n",
    "    # split dataset into train and test+dev\n",
    "    train_idx, test_idx, train_label, test_label = train_test_split(\n",
    "        x, y, test_size=0.2, stratify=y\n",
    "    )\n",
    "\n",
    "    train_idx.sort()\n",
    "    test_idx.sort()\n",
    "\n",
    "    train_dataset = dataset.subset(train_idx)\n",
    "    test_dataset = dataset.subset(test_idx)\n",
    "\n",
    "    print(\n",
    "        f\"train_dataset: {len(train_dataset)} | test_dataset: {len(test_dataset)}\",\n",
    "    )\n",
    "\n",
    "    # save into cache\n",
    "    file_name = f\"dataset_{i+1:02}.pt\"\n",
    "    file_path = os.path.join(SAVE_DIR_ONLINE, file_name)\n",
    "    torch.save(\n",
    "        {\n",
    "            \"train\": train_dataset,\n",
    "            \"test\": test_dataset,\n",
    "        },\n",
    "        file_path,\n",
    "    )\n",
    "    print(f\"Saved {file_name} with size: {os.path.getsize(file_path)} bytes\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
